{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amittian/basics_of_langchain/blob/main/01_langchain_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "288ce9a8",
      "metadata": {
        "id": "288ce9a8"
      },
      "source": [
        "# LangChain Basics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wziSRm_50FnR",
        "outputId": "44f7e1ad-b75b-4adf-e1fe-1cd91536f68e"
      },
      "id": "wziSRm_50FnR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab_Notebooks/LLM_ops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCpDFLlR1HA3",
        "outputId": "d6783c02-d729-4c2a-8cec-d29c5fb6deef"
      },
      "id": "eCpDFLlR1HA3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/LLM_ops\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "002d92f1",
      "metadata": {
        "id": "002d92f1"
      },
      "outputs": [],
      "source": [
        "# installing the required libraries\n",
        "!pip install -r ./requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ff28727",
      "metadata": {
        "id": "4ff28727"
      },
      "outputs": [],
      "source": [
        "# !pip - installs the packages in the base environment\n",
        "# pip - installs the packages in the virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bdf2f431",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdf2f431",
        "outputId": "51686a3d-af1b-4824-f465-7ad9746c6fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.233\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "pip show langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d14256a6",
      "metadata": {
        "id": "d14256a6"
      },
      "outputs": [],
      "source": [
        "# upgrading langchain\n",
        "!pip install langchain --upgrade -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4407a3a",
      "metadata": {
        "id": "f4407a3a"
      },
      "source": [
        "#### Python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d9420415",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d9420415",
        "outputId": "e43eb135-2f1c-4ce4-a0f0-03e19156955b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4569864d-d5d0-466e-b92e-05cb4c439e5d'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# loading the API Keys (OpenAI, Pinecone) from .env\n",
        "load_dotenv(find_dotenv(), override=True)\n",
        "\n",
        "os.environ.get('PINECONE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e29231e2",
      "metadata": {
        "id": "e29231e2"
      },
      "source": [
        "### LLM Models (Wrappers): GPT-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8d37cc56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d37cc56",
        "outputId": "f0bba8fc-11c2-4c30-a13a-a1ffb3cde508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mOpenAI\u001b[0m\n",
            "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
        "\n",
        "# In this case, since we want the outputs to be MORE random, we'll initialize our model with a HIGH temperature.\n",
        "print(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5d355809",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d355809",
        "outputId": "2a662aca-73bc-4942-bec4-2b13e57f3a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Quantum mechanics is a physical theory that describes the behavior and interaction of subatomic particles on the quantum level.\n"
          ]
        }
      ],
      "source": [
        "output = llm('explain quantum mechanics in one sentence')\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e29c5e84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e29c5e84",
        "outputId": "6f913b37-fd41-4b56-805a-899459edd66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "print(llm.get_num_tokens('explain quantum mechanics in one sentence'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d00248e0",
      "metadata": {
        "id": "d00248e0"
      },
      "outputs": [],
      "source": [
        "output = llm.generate(['... is the capital of France.',\n",
        "                   'What is the formula for the area of a circle?'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b98fd88a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b98fd88a",
        "outputId": "0f03265e-cc63-46af-a6ac-d55315a4a05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[Generation(text='\\n\\nParis', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where A is the area of the circle, and r is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
          ]
        }
      ],
      "source": [
        "print(output.generations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e0725e38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0725e38",
        "outputId": "f34a1b33-a538-4b4a-f723-c55330bdaab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Paris\n"
          ]
        }
      ],
      "source": [
        "print(output.generations[0][0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7703b86d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7703b86d",
        "outputId": "1e16d9e9-2df2-4814-f6b2-08ff66a3e3fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(output.generations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "779b3a6b",
      "metadata": {
        "id": "779b3a6b"
      },
      "outputs": [],
      "source": [
        "output = llm.generate(['Write an orignal tagline for a burger restaurant'] * 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1d3cdfd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3cdfd8",
        "outputId": "35fa23bd-82bc-4bf8-bf57-8454a63822cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Taste the Juicy Difference!\"\n",
            "\n",
            "\"Taste the Juicy Difference!\"\n",
            "\n",
            "\"Experience the Burger Craze at Our Joint!\""
          ]
        }
      ],
      "source": [
        "for o in output.generations:\n",
        "    print(o[0].text, end='')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c20ee709",
      "metadata": {
        "id": "c20ee709"
      },
      "source": [
        "### ChatModels: GPT-3.5-Turbo and GPT-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "054eadaa",
      "metadata": {
        "id": "054eadaa"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import(\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f9bdecaa",
      "metadata": {
        "collapsed": true,
        "id": "f9bdecaa"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
        "\n",
        "# if we want to use the 'gpt-4' instead of 'gpt-3.5-turbo'\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
        "    HumanMessage(content='explain quantum mechanics in one sentence')\n",
        "]\n",
        "output = chat(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "761e06dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "761e06dd",
        "outputId": "486b8d8b-cc6c-49c8-dd00-85e2601fae2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantenmechanik beschreibt das Verhalten von Teilchen auf atomarer und subatomarer Ebene durch Wahrscheinlichkeitsverteilungen und Wellenfunktionen.\n"
          ]
        }
      ],
      "source": [
        "print(output.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3ad29b",
      "metadata": {
        "id": "6d3ad29b"
      },
      "source": [
        "### Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3a31ca4b",
      "metadata": {
        "id": "3a31ca4b"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "612ed8a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "612ed8a8",
        "outputId": "95b0c353-8ac5-48a9-e43f-5bec94c5f3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['virus', 'language'] output_parser=None partial_variables={} template='You are an experienced virologist.\\nWrite a few sentences about the following {virus} in {language}.' template_format='f-string' validate_template=True\n"
          ]
        }
      ],
      "source": [
        "template = '''You are an experienced virologist.\n",
        "Write a few sentences about the following {virus} in {language}.'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['virus', 'language'],\n",
        "    template=template\n",
        ")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b28accc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b28accc9",
        "outputId": "b3437ecd-1ca7-400b-c5e0-bdfba45da6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "HIV ist ein Virus, das das menschliche Immunsystem schädigt und AIDS verursacht. Es wird hauptsächlich durch ungeschützten Geschlechtsverkehr, das Sharing von Injektionsnadeln und von einer infizierten Mutter auf ihr ungeborenes Kind übertragen. Es gibt keine Heilung für HIV, aber mit der richtigen Behandlung können die Symptome und Komplikationen bei einer Infektion kontrolliert werden.\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
        "output = llm(prompt.format(virus='HIV', language='German'))\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
        "output = llm(prompt.format(virus='covid', language='english'))\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iKXiM0MdyHK",
        "outputId": "4e597c3c-339c-4290-a476-d8a4f6e57ffc"
      },
      "id": "8iKXiM0MdyHK",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Coronavirus disease 2019 (COVID-19) is a contagious respiratory illness caused by a novel coronavirus first identified in Wuhan, China in late 2019. It has since spread around the world, resulting in millions of cases and hundreds of thousands of deaths. Symptoms of COVID-19 include fever, dry cough, fatigue, body aches, and difficulty breathing. Treatment is supportive and includes rest, hydration, and medications to reduce symptoms. Vaccines are in development, but are not yet widely available. The best way to prevent the spread of COVID-19 is to take preventive measures such as washing your hands often, wearing a face mask, and avoiding close contact with others.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "025d9b84",
      "metadata": {
        "id": "025d9b84"
      },
      "source": [
        "### Simple Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fd1e5278",
      "metadata": {
        "id": "fd1e5278"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
        "template = '''You are an experienced virologist.\n",
        "Write a few sentences about the following {virus} in {language}.'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['virus', 'language'],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "output = chain.run({'virus': 'HSV', 'language': 'french'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "be42818a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be42818a",
        "outputId": "c69f62b1-70a8-40ab-9db4-ff3f414da958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L'HSV, ou Herpes Simplex Virus, est un virus à ADN appartenant à la famille des Herpesviridae. Il existe deux types d'HSV : le HSV-1, qui est principalement responsable des infections buccales et labiales, et le HSV-2, qui est principalement responsable des infections génitales. Ces virus sont très répandus et peuvent se transmettre par contact direct avec les lésions cutanées ou les muqueuses d'une personne infectée. Une fois infecté, le virus peut rester latent dans les ganglions nerveux et se réactiver périodiquement, provoquant des poussées d'infections récurrentes.\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_one = '''You are an experienced virologist.\n",
        "Write a few sentences about the following {virus} .'''\n",
        "\n",
        "\n",
        "prompt_one = PromptTemplate(\n",
        "    input_variables=['virus'] ,\n",
        "    template=template_one\n",
        ")\n",
        "\n",
        "chain_one = LLMChain(llm=llm, prompt=prompt_one)\n",
        "# output_english = chain_one.run({'virus': 'covid', 'language': 'english'})\n",
        "\n",
        "output_english = chain_one.run('covid')\n",
        "print(output_english)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSPp-Lopi8ge",
        "outputId": "156a31d3-b059-4297-c76b-c82d1e1a58c9"
      },
      "id": "PSPp-Lopi8ge",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COVID-19, also known as the novel coronavirus, is a highly contagious respiratory illness caused by the SARS-CoV-2 virus. It was first identified in Wuhan, China in late 2019 and has since spread globally, leading to a pandemic. The virus primarily spreads through respiratory droplets when an infected person coughs, sneezes, or talks, making it crucial to practice good hygiene and maintain social distancing to prevent transmission. Symptoms of COVID-19 can range from mild to severe, with fever, cough, and difficulty breathing being the most common. As a virologist, I am dedicated to studying the virus, its transmission patterns, and developing effective prevention strategies and treatments to combat this global health crisis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f283cc13",
      "metadata": {
        "id": "f283cc13"
      },
      "source": [
        "### Sequential Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9d68115d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d68115d",
        "outputId": "fe6f22f7-1476-4c27-87ad-3551527813ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "def sigmoid(x):\n",
            "  return 1/(1+math.exp(-x))\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe given Python function 'sigmoid' is used to calculate the sigmoid function. The sigmoid function is a mathematical function that maps any real number to a value between 0 and 1. \n",
            "\n",
            "In the function, the input 'x' is passed as a parameter to the math.exp() function, which computes the exponential value of 'x'. The negative value of 'x' is passed to the exp() function due to the mathematical formula of the sigmoid function. \n",
            "\n",
            "The output of the exp() function is then added to 1, and this sum is used as the denominator of the division operation. The numerator of the division is 1. \n",
            "\n",
            "The division operation is performed by using the '/' operator, which calculates the quotient. \n",
            "\n",
            "By dividing 1 by the value from the sum of exp(-x) and 1, the sigmoid function returns a value between 0 and 1, representing the probability or 'activation' of a given input.\n",
            "\n",
            "To summarize, the function sigmoid(x) returns the calculated sigmoid value for the input 'x', which ranges between 0 and 1, denoting the likelihood or activation level of a particular input value. This function is commonly used in machine learning, neural networks, and logistic regression to introduce non-linearity and map values to constrained ranges.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
        "prompt1 = PromptTemplate(\n",
        "    input_variables=['concept'],\n",
        "    template='''You are an experienced scientist and Python programmer.\n",
        "    Write a function that implements the concept of {concept}.'''\n",
        ")\n",
        "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
        "\n",
        "\n",
        "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
        "prompt2 = PromptTemplate(\n",
        "    input_variables=['function'],\n",
        "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
        ")\n",
        "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
        "output = overall_chain.run('sigmoid function')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_two = overall_chain.run('softmax')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kABe-yMZpi37",
        "outputId": "c85ab593-1ca8-45d9-a45b-41c98825e0ec"
      },
      "id": "kABe-yMZpi37",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "def softmax(x):\n",
            "  \"\"\"Compute softmax values for each sets of scores in x.\"\"\" \n",
            "  return np.exp(x) / np.sum(np.exp(x), axis=0)\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe given Python function softmax(x) takes in an array-like object x as input and returns the softmax values for each set of scores in x. The softmax function is often used in machine learning models to convert a vector of real values into a probability distribution.\n",
            "\n",
            "Here is a detailed description of the function:\n",
            "\n",
            "1. The function begins with a docstring (documentation string) enclosed in triple quotes \"\"\". This docstring provides a brief description of the function's purpose.\n",
            "\n",
            "2. Inside the function, np.exp(x) computes the exponentiation of each element in the input array x. This calculates e^x for each value, where e is Euler's number (approximately 2.71828).\n",
            "\n",
            "3. The result of np.exp(x) is then divided by np.sum(np.exp(x), axis=0). np.sum computes the sum along the specified axis (0 in this case), which will sum all the exponentiated values for each column if x is a multi-dimensional array. This step normalizes the exponentiated values by dividing each element by the sum of all exponentiated values.\n",
            "\n",
            "4. The final result is the softmax values, which represent a probability distribution where each value is between 0 and 1, and their sum is equal to 1. These values indicate the likelihood that each element in x belongs to a particular class or category.\n",
            "\n",
            "Overall, the softmax function is used to map an array of arbitrary real values to a valid probability distribution, which is commonly required in classification tasks.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_two = overall_chain.run('confusion matrix')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIwIhnYTpv0h",
        "outputId": "956bae91-d7c2-495c-85c1-f01d0ae71e0d"
      },
      "id": "NIwIhnYTpv0h",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "def confusion_matrix(actual_values, predicted_values):\n",
            "    \"\"\"\n",
            "    Function to calculate and display a confusion matrix.\n",
            "\n",
            "    Parameters\n",
            "    ----------\n",
            "    actual_values : list of int\n",
            "        List of actual values/classes in the dataset.\n",
            "    predicted_values : list of int\n",
            "        List of predicted values/classes in the dataset.\n",
            "\n",
            "    Returns\n",
            "    -------\n",
            "    confusion_matrix : 2D numpy array\n",
            "        A 2D numpy array representing the confusion matrix.\n",
            "    \"\"\"\n",
            "\n",
            "    # Initialize a confusion matrix\n",
            "    confusion_matrix = np.zeros((len(actual_values), len(predicted_values)))\n",
            "    \n",
            "    # Calculate the confusion matrix\n",
            "    for i in range(len(actual_values)):\n",
            "        for j in range(len(predicted_values)):\n",
            "            confusion_matrix[i][j] = np.sum(np.where(actual_values == i, 1, 0) * np.where(predicted_values == j, 1, 0))\n",
            "    \n",
            "    # Return the confusion matrix\n",
            "    return confusion_matrix\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe given Python function is named `confusion_matrix` and is used to calculate and display a confusion matrix. \n",
            "\n",
            "A confusion matrix is a table that is often used to describe the performance of a classification model. It displays the number of true positive, true negative, false positive, and false negative predictions made by the model on a dataset.\n",
            "\n",
            "The function takes two parameters:\n",
            "- `actual_values`: a list of integers representing the actual values/classes in the dataset.\n",
            "- `predicted_values`: a list of integers representing the predicted values/classes in the dataset.\n",
            "\n",
            "The function returns a 2D numpy array representing the confusion matrix. \n",
            "\n",
            "In the function implementation, the confusion matrix is initialized as a 2D numpy array of zeros with dimensions `(len(actual_values), len(predicted_values))`. This ensures that each value in `actual_values` and `predicted_values` has a corresponding row and column in the confusion matrix.\n",
            "\n",
            "The confusion matrix is then calculated using nested for loops. For each `i`th element in `actual_values` and `j`th element in `predicted_values`, it calculates the sum of the product of two 1D numpy arrays. \n",
            "\n",
            "The first numpy array is the result of `np.where(actual_values == i, 1, 0)`, which creates a binary array where the value is 1 if the corresponding element in `actual_values` is equal to `i`, otherwise it is 0.\n",
            "\n",
            "The second numpy array is the result of `np.where(predicted_values == j, 1, 0)`, which creates a binary array where the value is 1 if the corresponding element in `predicted_values` is equal to `j`, otherwise it is 0.\n",
            "\n",
            "Multiplying these two arrays together creates a new array where the value is 1 only if both conditions are satisfied (i.e., the actual value is `i` and the predicted value is `j`), otherwise it is 0. The sum of this array gives the count of such occurrences.\n",
            "\n",
            "These counts are then assigned to the corresponding cell of the confusion matrix.\n",
            "\n",
            "Finally, the function returns the calculated confusion matrix.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3a9c39",
      "metadata": {
        "id": "ed3a9c39"
      },
      "source": [
        "### LangChain Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "631fd9cf",
      "metadata": {
        "id": "631fd9cf"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "115e2fe3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "115e2fe3",
        "outputId": "d2b6a12c-28c3-4311-d7e7-0c8ae3f5478d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to use the Python REPL to calculate this\n",
            "Action: Python_REPL\n",
            "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 146306.05007233328\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'146306.05007233328'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "agent_executor = create_python_agent(\n",
        "    llm=llm,\n",
        "    tool=PythonREPLTool(),\n",
        "    verbose=True\n",
        ")\n",
        "# agent_executor.run('Calculate the square root of the factorial of 20 \\\n",
        "# and display it with 4 decimal points')\n",
        "\n",
        "agent_executor.run('what is the answer to 5.1 ** 7.3?')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8f0af1eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "8f0af1eb",
        "outputId": "f377daee-8c61-4a13-b722-ff8bca3b68e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to calculate the factorial of 6\n",
            "Action: Python_REPL\n",
            "Action Input: print(6*5*4*3*2*1)\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m720\n",
            "\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-Y8c8E8ch0vgmHyHgnqMHNF2c on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 720\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'720'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "agent_executor.run('what is the answer to factorial 6')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igDptbdItzh7"
      },
      "id": "igDptbdItzh7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}